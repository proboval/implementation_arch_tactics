## Topic: Pattern-Tactic Interaction & Architecture Erosion (Section 2.3)

**Papers:** 10 | **Updated:** 2026-02-16

### Summary

Architectural tactics, as originally defined by Bass et al. (2003) and formalized by Kim et al. (2009), are fine-grained, reusable architectural building blocks that provide design decisions influencing the control of a quality attribute response. Kim et al. demonstrated that tactics can be rigorously specified using feature models (capturing variability relationships: mandatory, optional, requires, suggested, mutually exclusive) combined with RBML structural and behavioral semantics, enabling systematic composition and automated architecture instantiation. However, Kim's formalization covers only availability, performance, and security tactics -- modifiability is explicitly deferred as future work, and "not all tactics can be specified in the RBML" due to their abstract nature. Marquez et al. (2022), in the most comprehensive systematic mapping study of the tactics landscape (91 primary studies, 2003--2021, co-authored by Kazman), reveal a sobering reality: 71% of studies do not describe how tactics were identified, 69% omit data source descriptions, and 59% lack tactic characterization mechanisms. Security dominates with 18 studies while modifiability -- the quality attribute closest to ISO 25010 maintainability -- has received exactly one dedicated study. Marquez concludes that "most tactics proposed in the literature do not conform to the original definition" and that "automation opportunities beckon within reach."

The interaction between patterns and tactics is not merely additive but structurally transformative. Harrison and Avgeriou (2010) provide the definitive taxonomy of these interactions, identifying five types of structural changes (Implemented-in, Replicates, Add-in-pattern, Add-out-of-pattern, Modify -- ordered by increasing impact) and two categories of behavioral changes (action sequence additions and timing modifications). Their five-point impact magnitude scale (Good Fit ++ to Poor Fit --) demonstrates that compatibility varies widely: in Pipes-and-Filters, Voting/Active Redundancy achieves Good Fit (++) while Ping/Echo receives Poor Fit (--). Critically, Harrison observes that "implementing tactics is actually a form of architecture drift" and documents a snowball effect in Case Study 3 where a layer-bypass for performance forced duplicate authorization components, directly degrading maintainability. This finding is corroborated by Kassab et al. (2018), whose survey of 809 software professionals reveals that 63% of projects modify architectural patterns with tactics during implementation, confirming that patterns are rarely applied as prescribed. Bogner et al. (2019) extend this analysis to service-oriented systems, mapping 15 modifiability tactics (Increase Cohesion: 5, Reduce Coupling: 4, Defer Binding Time: 6) onto SOA and Microservices patterns, finding that SOA achieves modifiability through governance and standardization while Microservices rely on evolutionary design and infrastructure automation -- yet only 3 of 21 mapped Microservices patterns address cohesion despite it being a core philosophy.

Architecture erosion and drift represent the degradation that occurs when tactic-pattern interactions are poorly managed. Li et al. (2021) provide a comprehensive taxonomy from 73 primary studies, defining architecture erosion from four perspectives (violation, structure, quality, evolution) and identifying 13 categories of causes, with architecture violation (24.7%), evolution issues (23.3%), and technical debt (17.8%) as the top technical reasons. They find that 83.8% of consequence-mentioning studies report quality degradation, with maintainability, evolvability, and extensibility most affected, and that technical debt forms a vicious cycle with erosion. Rosik et al. (2011) provide complementary empirical evidence from a 2-year longitudinal study at IBM, demonstrating that drift occurs even during de novo development by a single architect-developer, and -- most importantly -- that "inconsistency identification alone does not lead to inconsistency removal." Developers tolerated all 9 identified divergences due to risk of ripple effects and time pressure. This finding directly motivates the thesis: detection without low-cost remediation is insufficient. Meanwhile, Bi et al. (2021) mine 4,195 verified QA-AT posts from Stack Overflow, discovering that ~21% of practitioner-discussed QA-AT relationships are "little-known" (undocumented in literature), with specific tactics like Time stamp, Sanity checking, and Analytical redundancy benefiting Maintainability while Resource pooling can hinder it. The detection-implementation gap is crystallized by two tools: Ge et al. (2022) present ArchTacRV, which detects tactic behavioral methods in code and verifies runtime behavioral consistency against RBML specifications across 74 open-source projects and 10 tactic types -- but only detects, never implements. Shokri et al. (2024) present IPSynth, the closest existing work to automated tactic implementation, achieving 85% semantic correctness on 20 inter-procedural tactic synthesis tasks through specification-driven program synthesis with SMT solving. Critically, their comparative evaluation shows ChatGPT achieves only 5% semantic correctness (1/20 tasks) on the same benchmark -- syntactically correct (95% compilable) but semantically wrong -- because LLMs fail at cross-method, cross-class dependency preservation. IPSynth's limitation is that it uses formal program synthesis (not LLMs), covers only JAAS security tactics, and produces loop-free code only.

### Key Papers
| Paper | Contribution | Relevance |
|-------|--------------|-----------|
| `marquez2022architectural` | Definitive SMS of 91 studies: 71% lack identification method, modifiability has 1 study, "automation opportunities beckon" | CRITICAL |
| `harrison2010how` | Taxonomy of 5 structural + 2 behavioral pattern-tactic interaction types; five-point impact scale; drift as snowball effect | CRITICAL |
| `shokri2024ipsynth` | IPSynth: 85% semantic correctness for automated tactic implementation via program synthesis; ChatGPT baseline at 5% | CRITICAL |
| `kim2009qualitydriven` | Feature-model tactic formalization with RBML; composition rules; modifiability deferred as future work | HIGH |
| `li2021understanding` | Architecture erosion SMS (73 studies): 4-perspective definition, 13 cause categories, vicious TD cycle | HIGH |
| `rosik2011assessing` | 2-year IBM case study: detection without remediation is insufficient; developers tolerate all violations | HIGH |
| `bi2021mining` | 4,195 SO posts mined: 21 ATs x 8 QAs mapping; 21% "little-known" relationships; maintainability-specific ATs | HIGH |
| `bogner2019modifiability` | 15 modifiability tactics mapped to SOA/Microservices patterns; Reduce Coupling dominant; cohesion gap | HIGH |
| `ge2022archtacrv` | ArchTacRV: ML-based tactic detection + runtime verification across 74 projects; detection-only, no implementation | HIGH |
| `kassab2018software` | 809-professional survey: 63% modify patterns with tactics; functionality (not quality) drives pattern selection | MEDIUM |

### Tactic Taxonomy
| Quality Attribute | # Tactics (Bass et al.) | Detection Tools | Implementation Tools |
|-------------------|------------------------|-----------------|---------------------|
| Security | 18 studies (Marquez); Authentication, Authorization, Encryption, Restoration (Kim) | ARCODE, ArchEngine, BERT classifiers, SVM, ArchTacRV | IPSynth (JAAS only, 85% correctness) |
| Availability | 4 studies; Fault Detection (Ping/Echo, Heartbeat, Exception), Recovery (Checkpoint/Rollback, State Resync), Repair (Voting, Active/Passive Redundancy) (Kim) | ARCODE, ArchTacRV, Archie | None automated |
| Performance | 4 studies; Resource Arbitration (FIFO, Fixed/Dynamic Priority), Resource Management (Concurrency, Caching) (Kim) | Manual mapping, code analysis | None automated |
| Modifiability | **1 study** (Marquez); 15 tactics in 3 categories: Increase Cohesion (5), Reduce Coupling (4), Defer Binding Time (6) (Bogner/Bachmann) | Manual mapping, qualitative analysis only | **None -- thesis gap** |
| Fault Tolerance | 5 studies; Voting, Redundancy, Monitoring | ARCODE, ArchTacRV | None automated |
| Safety | 4 studies | Manual analysis | None automated |
| Scalability | Subset of performance/availability | Limited | None automated |

### Pattern-Tactic Interaction Types
| Type | Category | Description | Source |
|------|----------|-------------|--------|
| Implemented-in | Structural | Tactic behavior added within existing component; no new components or connectors | Harrison 2010 |
| Replicates | Structural | Existing component duplicated to realize tactic; new connectors to replicas | Harrison 2010 |
| Add-in-pattern | Structural | New component added within existing pattern structure; new connectors within pattern | Harrison 2010 |
| Add-out-of-pattern | Structural | New component added outside pattern structure; connectors cross pattern boundary; causes drift | Harrison 2010 |
| Modify | Structural | Existing component fundamentally altered in structure; highest structural impact | Harrison 2010 |
| Action sequence addition | Behavioral | New action sequences added within or outside existing behavioral sequences | Harrison 2010 |
| Timing modification | Behavioral | New explicit/implicit timing constraints added, or existing timing changed (4 sub-types) | Harrison 2010 |

### Architecture Erosion & Drift
| Concept | Definition | Detection Method | Source |
|---------|------------|-----------------|--------|
| Architecture Erosion | "Happens when the implemented architecture violates the intended architecture with flawed internal structure or when architecture becomes resistant to change" (refined from 4 perspectives: violation, structure, quality, evolution) | Consistency-based (62.5%), evolution-based (22.5%), defect-based (15.0%); 35 tools, 57.1% use Architecture Conformance Checking | Li 2021 |
| Architecture Drift | Divergence of implemented from designed architecture during development; occurs even in de novo development by single architect-developer | Reflexion Modelling (jRMTool); periodic evaluation sessions | Rosik 2011 |
| Tactic-induced Drift | "Implementing tactics is actually a form of architecture drift" -- adding components outside pattern structure has snowball effect (e.g., layer-bypass forces duplicate authorization) | Architecture review + annotation method; manual inspection of tactic locations | Harrison 2010 |
| Knowledge Vaporization | Loss of architectural knowledge as developers leave; 15.1% of erosion studies cite this as cause | Documentation analysis, expert interviews | Li 2021 |
| Technical Debt Cycle | TD is both a cause and consequence of erosion, forming a vicious cycle | Metric-based, defect tracking | Li 2021 |
| Detection-Remediation Gap | Identifying inconsistencies does not lead to removal; developers tolerate violations due to ripple-effect risk and time pressure (0 of 9 violations fixed at IBM) | Reflexion Modelling detected violations; retrospective interviews confirmed deliberate tolerance | Rosik 2011 |

### Consensus
| Finding | Papers | Confidence |
|---------|--------|------------|
| Tactics are building blocks from which patterns are created; patterns "package" tactics | `kim2009qualitydriven`, `harrison2010how`, `marquez2022architectural`, `kassab2018software`, `bogner2019modifiability` | High |
| Patterns are rarely applied as prescribed -- practitioners modify them with tactics | `kassab2018software` (63% modify), `harrison2010how` (all 3 case studies), `bi2021mining` (47% discuss patterns) | High |
| Tactic implementation can cause architecture drift/erosion if not managed | `harrison2010how` (snowball effect), `rosik2011assessing` (2-year evidence), `li2021understanding` (83.8% quality degradation) | High |
| Detection without remediation is insufficient | `rosik2011assessing` (0/9 fixed), `li2021understanding` (research-practice gap), `harrison2010how` (no automation) | High |
| Modifiability/maintainability tactics are severely under-researched | `marquez2022architectural` (1/91 studies), `kim2009qualitydriven` (explicitly future work), `bogner2019modifiability` (first mapping) | High |
| ML/NLP techniques can detect tactics in code but cannot implement them | `ge2022archtacrv` (detection+RV), `marquez2022architectural` (SVM, BERT cited), `bi2021mining` (SVM mining) | High |
| LLMs alone fail at inter-procedural tactic implementation | `shokri2024ipsynth` (ChatGPT 5% vs IPSynth 85%) | Medium (single study) |
| Practitioner knowledge extends beyond academic tactic catalogs | `bi2021mining` (21% "little-known" QA-AT relationships from SO) | Medium |

### Contradictions
| Issue | Position A | Position B | Thesis Choice |
|-------|------------|------------|---------------|
| Tactic formalization level | `kim2009qualitydriven`: Tactics can be rigorously formalized via RBML + feature models | `marquez2022architectural`: Most proposed tactics (71%) lack any formal identification method; many don't conform to original definition | Adopt Kim's formalization as target quality standard; acknowledge Marquez's finding that the field has not achieved this standard broadly |
| Automated vs. manual tactic selection | `kim2009qualitydriven`: Automated selection is feasible via metrics + inference (future work) | `harrison2010how`: Each pattern-tactic pair must be individually examined; subjective impact scale | Use LLM as a flexible intermediary -- encode Kim's feature-model constraints as prompt context while using Harrison's interaction types as guardrails |
| LLM capability for tactic implementation | `shokri2024ipsynth`: ChatGPT achieves only 5% semantic correctness on inter-procedural tasks | Thesis hypothesis: LLMs with architectural context, structured prompting, and iterative refinement can achieve higher accuracy than naive ChatGPT | Address IPSynth's critique by providing architectural context (pattern structure, tactic specifications) in prompts; use multi-step pipeline rather than single-shot generation; measure against IPSynth's 85% as upper baseline |
| SOA vs. Microservices modifiability strategy | `bogner2019modifiability`: SOA uses governance/standardization; Microservices use evolutionary design/automation | `bogner2019modifiability`: Microservices have cohesion gap (only 3/21 patterns) despite cohesion being core philosophy | Focus thesis on general backend modifiability tactics applicable across architectural styles; avoid style-specific assumptions |

### Detection vs Implementation Gap
| Aspect | Detection (Current) | Implementation (Gap) | Thesis Response |
|--------|--------------------|--------------------|----------------|
| **Tactic identification** | ML classifiers (SVM, Decision Tree, BERT) detect tactics in code (Marquez 2022, Ge 2022); 71% of studies don't even describe identification method | No tool transforms detection results into code changes; detection produces reports, not implementations | LLM pipeline transforms detected architecture patterns into implemented tactics using structured prompts with tactic specifications |
| **Architecture conformance** | Reflexion Modelling (Rosik 2011), ArchTacRV (Ge 2022), 35 tools in Li 2021 (57.1% ACC-based) | Conformance checking identifies violations but provides no remediation; developers tolerate 100% of found violations (Rosik) | LLM generates the remediation code, lowering the cost/risk barrier that prevents developers from fixing violations |
| **Tactic specification** | RBML (Kim 2009), FSpec API models (IPSynth/ArCode), qualitative mappings (Bogner 2019) | Specifications exist as formal models but not as actionable transformation instructions | Translate RBML/feature-model specifications into LLM prompt templates encoding what structural/behavioral changes each tactic requires |
| **Inter-procedural synthesis** | IPSynth (Shokri 2024): 85% correctness via SMT solving + API usage models | Formal synthesis limited to single framework (JAAS), loop-free code, Java only; ChatGPT alone achieves 5% | Combine LLM flexibility (multi-language, complex code) with architectural context and iterative verification to improve on naive LLM performance |
| **Quality attribute impact** | Bi 2021 maps 21 ATs to 8 QAs from practitioner knowledge; Harrison 2010 provides 5-point impact magnitude scale | No tool predicts or measures the actual maintainability impact of implementing a specific tactic in a specific codebase | Pipeline includes before/after static analysis measurement (multi-tool) to quantify maintainability change from tactic implementation |
| **Practitioner knowledge** | Stack Overflow mining reveals 21% undocumented QA-AT relationships (Bi 2021); 809-professional survey confirms pattern modification is standard practice (Kassab 2018) | Practitioner knowledge exists implicitly but is not encoded in automation tools | LLM can leverage encoded practitioner knowledge (tactic catalogs, interaction types) as structured prompt context |
| **Erosion prevention** | 13 categories of erosion causes identified (Li 2021); detection tools exist but language-specific (>50% support only one language) | No automated tool prevents erosion by proactively implementing correct tactics; all tools are reactive | Pipeline implements tactics following Harrison's interaction-type guidelines to minimize drift-inducing changes (prefer Implemented-in over Add-out-of-pattern) |

### Gaps
| Gap | Impact on Thesis |
|-----|-----------------|
| **Modifiability has only 1 dedicated study** in 91 primary studies on architectural tactics (Marquez 2022) | Thesis directly addresses this gap by focusing on maintainability/modifiability tactics -- one of the most under-researched quality attributes in the tactics literature |
| **No automated implementation** of architectural tactics using LLMs exists; IPSynth uses program synthesis, not LLMs | Thesis provides the first LLM-based approach to automated tactic implementation, addressing Marquez's "automation opportunities beckon within reach" |
| **Detection-remediation disconnect**: tools detect violations but developers don't fix them (Rosik 2011: 0/9 fixed) | Thesis bridges detection and remediation by automating the implementation step, reducing the cost/risk barrier |
| **ChatGPT fails at inter-procedural tasks** (5% semantic correctness in IPSynth evaluation) | Thesis must demonstrate that structured architectural context + multi-step pipeline + iterative refinement improve LLM performance beyond naive single-shot generation |
| **No empirical data on maintainability impact** of tactic implementation (Harrison's impact scale is qualitative, subjective) | Thesis provides quantitative before/after measurement using static analysis metrics (multi-tool validation per Lenarduzzi 2023 findings) |
| **Pattern-tactic interaction types not operationalized** for automation (Harrison's 7 types remain manual annotations) | Thesis can use interaction types as classification framework for LLM-generated changes: prefer lower-impact types (Implemented-in, Add-in-pattern) to minimize drift |
| **Practitioner knowledge gap**: 21% of QA-AT relationships from SO are undocumented (Bi 2021) | Thesis can incorporate practitioner-discovered relationships (especially maintainability-specific ones) into tactic selection logic |
| **Language-specific tool limitation**: >50% of erosion detection tools support only one language (Li 2021) | LLM-based approach is inherently more language-flexible than traditional static analysis tools |
| **Bogner's modifiability mapping is qualitative only** -- no strength quantification for tactic-pattern mappings | Thesis can provide quantitative evidence through measured maintainability changes after implementing mapped tactics |
| **Kim's feature-model approach lacks maintainability coverage** -- covers availability, performance, security only | Thesis can extend Kim's methodology to maintainability tactics using Bogner's 15-tactic catalog as the starting taxonomy |

### Recommendations
**Adopt:**
- Harrison's 5 structural interaction types as the classification framework for LLM-generated changes (Implemented-in through Modify) -- use to predict transformation difficulty and guide the pipeline toward lower-impact, lower-drift implementations
- Bogner's 15 modifiability tactics (3 categories: Increase Cohesion, Reduce Coupling, Defer Binding Time) as the primary tactic catalog for the thesis
- Li's 4-perspective erosion definition and 13-cause taxonomy as the framework for defining "before" state metrics and evaluating whether tactic implementation reduces or increases erosion indicators
- Bi's QA-AT relationship matrix (including "little-known" relationships) as supplementary tactic selection knowledge

**Adapt:**
- Kim's feature-model formalization -- extend from availability/performance/security to maintainability tactics; translate feature-model relationships (requires, mutually exclusive) into prompt constraints for the LLM
- IPSynth's four-criteria scoring system (method name similarity, variable availability, control/data dependencies, code quality) -- adapt as evaluation criteria for LLM-generated tactic implementations
- Harrison's five-point impact magnitude scale -- operationalize it as a quantitative metric using static analysis deltas rather than subjective expert judgment

**Avoid:**
- Single-shot LLM generation for inter-procedural tactic implementation (IPSynth shows 5% correctness for ChatGPT); always use structured multi-step pipeline with architectural context
- Reliance on a single static analysis tool for impact measurement (Lenarduzzi 2023 shows <0.4% tool agreement); use multi-tool validation
- Attempting to formalize all tactics in RBML -- Kim acknowledges some tactics are too abstract; focus on structurally concrete modifiability tactics (Split Module, Use an Intermediary, Encapsulate) that have clear code-level manifestations
- Brownfield assumption without pattern identification -- Harrison shows pattern-tactic compatibility varies widely; the pipeline must first identify existing architectural patterns before selecting tactics

### Related Work Draft
> Architectural tactics, first introduced by Bass et al. and subsequently formalized by Kim et al. using feature models and RBML specifications, represent fine-grained, reusable building blocks that address specific quality attribute concerns within software architectures. Kim et al. demonstrated that tactics exhibit rich variability relationships (mandatory, optional, requires, suggested, mutually exclusive) and can be systematically composed for availability, performance, and security -- though they explicitly note that modifiability remains future work and that "not all tactics can be specified" due to their abstract nature. Harrison and Avgeriou developed the definitive model for pattern-tactic interaction, identifying five types of structural changes (Implemented-in, Replicates, Add-in-pattern, Add-out-of-pattern, and Modify) and two categories of behavioral changes, demonstrating through three industrial case studies that tactic implementation within patterns ranges from "Good Fit" to "Poor Fit" depending on the specific pattern-tactic pair. Their critical observation that "implementing tactics is actually a form of architecture drift" -- with documented snowball effects where one structural addition cascades into duplicated code and degraded maintainability -- establishes the central tension that this thesis addresses.
>
> The comprehensive systematic mapping study by Marquez et al., analyzing 91 primary studies from 2003 to 2021, reveals that the architectural tactics research landscape is characterized by significant methodological gaps: 71% of studies do not describe how tactics were identified, 69% omit data sources, and most proposed tactics do not conform to the original SEI definition. Most critically for this thesis, modifiability -- the quality attribute closest to ISO/IEC 25010 maintainability -- has received exactly one dedicated study out of 91, while security dominates with 18 studies. Bogner et al. partially address this imbalance by systematically mapping 15 modifiability tactics (organized as Increase Cohesion, Reduce Coupling, and Defer Binding Time) onto SOA and Microservices patterns, finding that "Reduce Coupling" dominates in both paradigms but that Microservices exhibit a surprising cohesion gap despite it being a core architectural philosophy. Bi et al. complement the academic perspective by mining 4,195 verified posts from Stack Overflow, revealing that approximately 21% of practitioner-discussed quality-attribute-to-tactic relationships are undocumented in the literature, including specific maintainability-relevant relationships such as the positive impact of Time stamp and Sanity checking tactics.
>
> Architecture erosion -- the progressive degradation that occurs when implemented architecture diverges from intended architecture -- provides the motivation for automated tactic remediation. Li et al.'s mapping study of 73 studies defines erosion from four perspectives (violation, structure, quality, and evolution), identifying that 83.8% of studies reporting erosion consequences cite quality degradation, with maintainability, evolvability, and extensibility most affected. Technical debt forms a vicious cycle with erosion, acting as both cause and consequence. Rosik et al.'s two-year longitudinal study at IBM provides the decisive empirical evidence: architectural drift occurs even during initial implementation by a sole architect-developer, and -- critically -- inconsistency identification alone does not lead to removal, as developers tolerate violations due to the risk of ripple effects and time pressure. This detection-remediation disconnect is the central gap that LLM-based automated tactic implementation aims to bridge. The closest existing approach, IPSynth by Shokri et al., achieves 85% semantic correctness on inter-procedural tactic synthesis tasks using specification-driven program synthesis with SMT solving, while their comparative evaluation shows that ChatGPT achieves only 5% correctness on the same benchmark -- producing syntactically valid but semantically incorrect implementations. However, IPSynth is limited to loop-free code within a single Java framework (JAAS security tactics), leaving the broader challenge of maintainability tactic implementation in diverse codebases unaddressed. The present thesis proposes that LLMs, when augmented with structured architectural context, tactic specifications, and iterative verification within a multi-step pipeline, can bridge the transformation gap between tactic detection and implementation for maintainability improvement.
